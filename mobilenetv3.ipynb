{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d478f01c",
   "metadata": {},
   "source": [
    "# Multi-Scenario MobileNetV3 Transfer Learning\n",
    "\n",
    "## Experiment Overview\n",
    "This notebook implements a comprehensive transfer learning experiment using **MobileNetV3Large** for rice leaf disease classification.\n",
    "\n",
    "### Dataset\n",
    "- **Original Classes**: 10 rice leaf disease categories\n",
    "- **Filtered Classes**: 4 selected classes\n",
    "  - bacterial_leaf_blight\n",
    "  - brown_spot\n",
    "  - leaf_blast\n",
    "  - healthy\n",
    "\n",
    "### Experiment Design\n",
    "**18 Training Scenarios** combining:\n",
    "- **3 Data Splits**: 90:10, 80:20, 70:30 (train:validation)\n",
    "- **2 Optimizers**: Adam, SGD\n",
    "- **3 Learning Rates**: 0.1, 0.01, 0.001\n",
    "- **3 Epoch Settings**: 15, 30, 45\n",
    "\n",
    "### Training Configuration\n",
    "| Scenario | Split Ratio | Optimizer | LR | Epochs |\n",
    "|----------|-------------|-----------|-----|--------|\n",
    "| 1-2 | 90:10 | Adam, SGD | 0.1 | 15 |\n",
    "| 3-4 | 90:10 | Adam, SGD | 0.01 | 30 |\n",
    "| 5-6 | 90:10 | Adam, SGD | 0.001 | 45 |\n",
    "| 7-8 | 80:20 | Adam, SGD | 0.1 | 15 |\n",
    "| 9-10 | 80:20 | Adam, SGD | 0.01 | 30 |\n",
    "| 11-12 | 80:20 | Adam, SGD | 0.001 | 45 |\n",
    "| 13-14 | 70:30 | Adam, SGD | 0.1 | 15 |\n",
    "| 15-16 | 70:30 | Adam, SGD | 0.01 | 30 |\n",
    "| 17-18 | 70:30 | Adam, SGD | 0.001 | 45 |\n",
    "\n",
    "### Method\n",
    "- **Transfer Learning**: Feature extraction with frozen MobileNetV3Large base\n",
    "- **Preprocessing**: Resize to 224\u00d7224, rescale to [0,1]\n",
    "- **Early Stopping**: Patience=5 epochs on validation loss\n",
    "- **Architecture**: MobileNetV3Large \u2192 GlobalAvgPool \u2192 Dropout(0.5) \u2192 Dense(4)\n",
    "\n",
    "### Outputs\n",
    "1. CSV file with all scenario results\n",
    "2. JSON file with training histories\n",
    "3. Top 10 scenarios bar chart\n",
    "4. Top 3 training curves\n",
    "5. Confusion matrix for best scenario\n",
    "6. Classification report for best scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f68553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  - Target classes: ['bacterial_leaf_blight', 'brown_spot', 'leaf_blast', 'healthy_rice_leaf']\n",
      "  - Number of classes: 4\n",
      "  - Image size: 224x224\n",
      "  - Batch size: 16\n",
      "  - Output directory: /workspaces/mobilnet-rice-leaf/work/results\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# =====================================================\n",
    "# MAIN TRAINING CODE\n",
    "# =====================================================\n",
    "import shutil\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input as preprocess_mobilenet\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Define AUTOTUNE for performance optimization\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# ------------------ 1. CONFIGURATION ------------------\n",
    "class Config:\n",
    "    BASE_INPUT = '/workspaces/mobilnet-rice-leaf/dataset/Rice_Leaf_AUG/Rice_Leaf_AUG'\n",
    "    WORK_DIR = '/workspaces/mobilnet-rice-leaf/work'\n",
    "    OUTPUT_DIR = '/workspaces/mobilnet-rice-leaf/work/results'\n",
    "    MODELS_DIR = '/workspaces/mobilnet-rice-leaf/work/models'\n",
    "    DATASET_DIR = '/workspaces/mobilnet-rice-leaf/work/dataset'\n",
    "    \n",
    "    # Target classes for filtering (4 out of 10 classes)\n",
    "    TARGET_CLASSES = ['bacterial_leaf_blight', 'brown_spot', 'leaf_blast', 'healthy_rice_leaf']\n",
    "    \n",
    "    BATCH_SIZE = 16\n",
    "    IMG_SIZE_MOBILE = 224\n",
    "    \n",
    "    # Model architecture\n",
    "    DROPOUT_RATE = 0.5\n",
    "    DENSE_UNITS = 256\n",
    "    NUM_CLASSES = 4  # Updated for 4 classes\n",
    "    \n",
    "    SEED = 42\n",
    "\n",
    "config = Config()\n",
    "\n",
    "if not os.path.exists(config.WORK_DIR):\n",
    "    print(f\"Creating working directory at: {config.WORK_DIR}\")\n",
    "    os.makedirs(config.WORK_DIR)\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"  - Target classes: {config.TARGET_CLASSES}\")\n",
    "print(f\"  - Number of classes: {config.NUM_CLASSES}\")\n",
    "print(f\"  - Image size: {config.IMG_SIZE_MOBILE}x{config.IMG_SIZE_MOBILE}\")\n",
    "print(f\"  - Batch size: {config.BATCH_SIZE}\")\n",
    "print(f\"  - Output directory: {config.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22624fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Working directory already exists\n"
     ]
    }
   ],
   "source": [
    "# ------------------ 2. DATASET FILTERING & PREPARATION ------------------\n",
    "\n",
    "def normalize_class_name(name):\n",
    "    \"\"\"\n",
    "    Normalize folder names to snake_case (lowercase, underscores).\n",
    "    \"\"\"\n",
    "    normalized = name.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    normalized = \"\".join(ch for ch in normalized if ch.isalnum() or ch == \"_\")\n",
    "    while \"__\" in normalized:\n",
    "        normalized = normalized.replace(\"__\", \"_\")\n",
    "    return normalized.strip(\"_\")\n",
    "\n",
    "def build_normalized_dir_map(source_dir):\n",
    "    \"\"\"\n",
    "    Map normalized folder names to their actual folder names in source_dir.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source_dir):\n",
    "        return {}\n",
    "    mapping = {}\n",
    "    for entry in os.listdir(source_dir):\n",
    "        entry_path = os.path.join(source_dir, entry)\n",
    "        if os.path.isdir(entry_path):\n",
    "            mapping[normalize_class_name(entry)] = entry\n",
    "    return mapping\n",
    "\n",
    "def filter_dataset_classes(source_dir, dest_dir, target_classes):\n",
    "    \"\"\"\n",
    "    Copy only the target classes from source to destination.\n",
    "    Preserves train/test directory structure.\n",
    "    \"\"\"\n",
    "        \n",
    "    if not os.path.exists(source_dir) and not os.path.exists(dest_dir):\n",
    "        return\n",
    "        \n",
    "    source_map = build_normalized_dir_map(source_dir)\n",
    "        \n",
    "    for class_name in target_classes:\n",
    "        normalized_name = normalize_class_name(class_name)\n",
    "        source_folder = source_map.get(normalized_name)\n",
    "        if not source_folder:\n",
    "            continue\n",
    "        source_class = os.path.join(source_dir, source_folder)\n",
    "        dest_class = os.path.join(dest_dir, normalized_name)\n",
    "        \n",
    "        if os.path.exists(source_class):\n",
    "            os.makedirs(dest_class, exist_ok=True)\n",
    "            if not os.listdir(dest_class):  # Only copy if destination is empty\n",
    "                shutil.copytree(source_class, dest_class, dirs_exist_ok=True)\n",
    "                print(f\"  Copied {source_folder} to {dest_class}/\")\n",
    "    \n",
    "    print(f\"\u2713 Dataset filtered to {len(target_classes)} classes\")\n",
    "\n",
    "# Copy and filter dataset\n",
    "if not os.path.exists(config.WORK_DIR):\n",
    "    # Create output directory for results\n",
    "    os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "    os.makedirs(config.MODELS_DIR, exist_ok=True)\n",
    "    os.makedirs(config.DATASET_DIR, exist_ok=True)\n",
    "    print(\"Filtering and copying dataset to working directory...\")\n",
    "    filter_dataset_classes(config.BASE_INPUT, config.DATASET_DIR, config.TARGET_CLASSES)\n",
    "else:\n",
    "    print(\"\u2713 Working directory already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b61bd5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Data generator function ready\n"
     ]
    }
   ],
   "source": [
    "# ------------------ 3. DATA SPLITTING & GENERATORS ------------------\n",
    "\n",
    "def preprocess_mobile(img, label):\n",
    "    \"\"\"\n",
    "    Preprocess images using MobileNetV3 preprocessing.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image tensor\n",
    "        label: Label tensor\n",
    "    \n",
    "    Returns:\n",
    "        Preprocessed image and label\n",
    "    \"\"\"\n",
    "    img = preprocess_mobilenet(img)\n",
    "    return img, label\n",
    "def create_data_generators(data_dir, train_ratio, img_size, batch_size):\n",
    "    \"\"\"\n",
    "    Create train/validation datasets with specified split ratio.\n",
    "    Uses tf.data.Dataset instead of ImageDataGenerator.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Data directory path\n",
    "        train_ratio: Ratio for training (e.g., 0.9 for 90:10 split)\n",
    "        img_size: Target image size\n",
    "        batch_size: Batch size for datasets\n",
    "    \n",
    "    Returns:\n",
    "        train_ds, val_ds, class_names\n",
    "    \"\"\"\n",
    "    # Calculate validation split\n",
    "    validation_split = 1.0 - train_ratio\n",
    "    \n",
    "    # Create training dataset\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=validation_split,\n",
    "        subset='training',\n",
    "        seed=SEED,\n",
    "        image_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Create validation dataset  \n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=validation_split,\n",
    "        subset='validation',\n",
    "        seed=SEED,\n",
    "        image_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = train_ds.class_names\n",
    "    \n",
    "    # Count total images in directory (efficient approach)\n",
    "    import glob\n",
    "    total_samples = sum(len(glob.glob(os.path.join(data_dir, class_name, '*'))) \n",
    "                       for class_name in class_names)\n",
    "    \n",
    "    # Calculate split counts\n",
    "    train_samples = int(total_samples * train_ratio)\n",
    "    val_samples = total_samples - train_samples\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    train_ds = train_ds.map(preprocess_mobile, AUTOTUNE).shuffle(1000).prefetch(AUTOTUNE)\n",
    "    val_ds = val_ds.map(preprocess_mobile, AUTOTUNE)\n",
    "    \n",
    "    # Store sample counts in a way compatible with existing code\n",
    "    # We wrap the dataset and add a samples property\n",
    "    class DatasetWithSamples:\n",
    "        def __init__(self, dataset, samples):\n",
    "            self._dataset = dataset\n",
    "            self.samples = samples\n",
    "        \n",
    "        def __iter__(self):\n",
    "            return iter(self._dataset)\n",
    "        \n",
    "        def __getattr__(self, name):\n",
    "            return getattr(self._dataset, name)\n",
    "    \n",
    "    train_ds_wrapper = DatasetWithSamples(train_ds, train_samples)\n",
    "    val_ds_wrapper = DatasetWithSamples(val_ds, val_samples)\n",
    "    \n",
    "    return train_ds_wrapper, val_ds_wrapper, class_names\n",
    "print(\"\u2713 Data generator function ready\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4330a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Created 18 training scenarios\n",
      "\n",
      "Scenario Summary:\n",
      "  Scenario 1: 90:10 split, Adam, LR=0.1, Epochs=15\n",
      "  Scenario 2: 90:10 split, SGD, LR=0.1, Epochs=15\n",
      "  Scenario 3: 90:10 split, Adam, LR=0.01, Epochs=30\n",
      "  ... and 15 more scenarios\n"
     ]
    }
   ],
   "source": [
    "# ------------------ 4. DEFINE 18 TRAINING SCENARIOS ------------------\n",
    "\n",
    "# Based on the table: 3 scenarios \u00d7 2 optimizers \u00d7 3 learning rates = 18 experiments\n",
    "scenarios = []\n",
    "\n",
    "scenario_configs = [\n",
    "    # Scenario 1: 90:10 split\n",
    "    {'split_ratio': 0.90, 'split_name': '90:10', 'lr': 0.1, 'epochs': 15},\n",
    "    {'split_ratio': 0.90, 'split_name': '90:10', 'lr': 0.01, 'epochs': 30},\n",
    "    {'split_ratio': 0.90, 'split_name': '90:10', 'lr': 0.001, 'epochs': 45},\n",
    "    \n",
    "    # Scenario 2: 80:20 split\n",
    "    {'split_ratio': 0.80, 'split_name': '80:20', 'lr': 0.1, 'epochs': 15},\n",
    "    {'split_ratio': 0.80, 'split_name': '80:20', 'lr': 0.01, 'epochs': 30},\n",
    "    {'split_ratio': 0.80, 'split_name': '80:20', 'lr': 0.001, 'epochs': 45},\n",
    "    \n",
    "    # Scenario 3: 70:30 split\n",
    "    {'split_ratio': 0.70, 'split_name': '70:30', 'lr': 0.1, 'epochs': 15},\n",
    "    {'split_ratio': 0.70, 'split_name': '70:30', 'lr': 0.01, 'epochs': 30},\n",
    "    {'split_ratio': 0.70, 'split_name': '70:30', 'lr': 0.001, 'epochs': 45},\n",
    "]\n",
    "\n",
    "optimizers_list = ['Adam', 'SGD']\n",
    "\n",
    "# Generate all 18 combinations\n",
    "scenario_id = 1\n",
    "for sc in scenario_configs:\n",
    "    for opt in optimizers_list:\n",
    "        scenarios.append({\n",
    "            'id': scenario_id,\n",
    "            'split_ratio': sc['split_ratio'],\n",
    "            'split_name': sc['split_name'],\n",
    "            'optimizer': opt,\n",
    "            'learning_rate': sc['lr'],\n",
    "            'epochs': sc['epochs']\n",
    "        })\n",
    "        scenario_id += 1\n",
    "\n",
    "print(f\"\u2713 Created {len(scenarios)} training scenarios\")\n",
    "print(\"\\nScenario Summary:\")\n",
    "for i, s in enumerate(scenarios[:3], 1):\n",
    "    print(f\"  Scenario {s['id']}: {s['split_name']} split, {s['optimizer']}, LR={s['learning_rate']}, Epochs={s['epochs']}\")\n",
    "print(f\"  ... and {len(scenarios)-3} more scenarios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f087a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Model builder function ready\n"
     ]
    }
   ],
   "source": [
    "# ------------------ 5. BUILD FEATURE EXTRACTION MODEL ------------------\n",
    "\n",
    "def build_feature_extraction_model(num_classes, img_size, optimizer_name, learning_rate, dropout_rate=0.5):\n",
    "    \"\"\"\n",
    "    Build MobileNetV3Large model for feature extraction (frozen base).\n",
    "    \n",
    "    Args:\n",
    "        num_classes: Number of output classes\n",
    "        img_size: Input image size\n",
    "        optimizer_name: 'Adam' or 'SGD'\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        dropout_rate: Dropout rate before output layer\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    # Load pre-trained MobileNetV3Large without top layers\n",
    "    base_model = MobileNetV3Large(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(img_size, img_size, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze all layers in base model (feature extraction)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build custom classification head\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(config.DENSE_UNITS, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Select optimizer\n",
    "    if optimizer_name == 'Adam':\n",
    "        opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        opt = optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"\u2713 Model builder function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85629957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STARTING TRAINING FOR 18 SCENARIOS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "SCENARIO 1/18\n",
      "  Split: 90:10\n",
      "  Optimizer: Adam\n",
      "  Learning Rate: 0.1\n",
      "  Epochs: 15\n",
      "======================================================================\n",
      "Found 5021 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 555 images belonging to 4 classes.\n",
      "  Training samples: 5021\n",
      "  Validation samples: 555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-16 08:59:04.767313: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-16 08:59:13.237541: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2026-02-16 08:59:13.263612: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 52301824 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     43\u001b[39m early_stop = callbacks.EarlyStopping(\n\u001b[32m     44\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     45\u001b[39m     patience=\u001b[32m5\u001b[39m,\n\u001b[32m     46\u001b[39m     restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     47\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     48\u001b[39m )\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     57\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Extract final metrics\u001b[39;00m\n\u001b[32m     60\u001b[39m final_train_acc = history.history[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    913\u001b[39m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[32m    914\u001b[39m   filtered_flat_args = (\n\u001b[32m    915\u001b[39m       \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn.function_type.unpack_inputs(\n\u001b[32m    916\u001b[39m           bound_args\n\u001b[32m    917\u001b[39m       )\n\u001b[32m    918\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    920\u001b[39m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[32m    925\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/mobilnet-rice-leaf/env/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ------------------ 6. TRAINING LOOP FOR ALL SCENARIOS ------------------\n",
    "results = []\n",
    "best_val_acc = float(\"-inf\")\n",
    "best_model_path = None\n",
    "best_scenario_id = None\n",
    "print(\"=\" * 70)\n",
    "print(f\"STARTING TRAINING FOR {len(scenarios)} SCENARIOS\")\n",
    "print(\"=\" * 70)\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SCENARIO {scenario['id']}/{len(scenarios)}\")\n",
    "    print(f\"  Split: {scenario['split_name']}\")\n",
    "    print(f\"  Optimizer: {scenario['optimizer']}\")\n",
    "    print(f\"  Learning Rate: {scenario['learning_rate']}\")\n",
    "    print(f\"  Epochs: {scenario['epochs']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    try:\n",
    "        # Create data generators for this split ratio\n",
    "        train_gen, val_gen, class_names = create_data_generators(\n",
    "            config.DATASET_DIR,\n",
    "            train_ratio=scenario['split_ratio'],\n",
    "            img_size=config.IMG_SIZE_MOBILE,\n",
    "            batch_size=config.BATCH_SIZE\n",
    "        )\n",
    "        print(f\"  Training samples: {train_gen.samples}\")\n",
    "        print(f\"  Validation samples: {val_gen.samples}\")\n",
    "        # Build model\n",
    "        model = build_feature_extraction_model(\n",
    "            num_classes=config.NUM_CLASSES,\n",
    "            img_size=config.IMG_SIZE_MOBILE,\n",
    "            optimizer_name=scenario['optimizer'],\n",
    "            learning_rate=scenario['learning_rate'],\n",
    "            dropout_rate=config.DROPOUT_RATE\n",
    "        )\n",
    "        # Callbacks\n",
    "        early_stop = callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=scenario['epochs'],\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "        # Extract final metrics\n",
    "        final_train_acc = history.history['accuracy'][-1]\n",
    "        final_train_loss = history.history['loss'][-1]\n",
    "        final_val_acc = history.history['val_accuracy'][-1]\n",
    "        final_val_loss = history.history['val_loss'][-1]\n",
    "        # Store results\n",
    "        result = {\n",
    "            'scenario_id': scenario['id'],\n",
    "            'split_ratio': scenario['split_name'],\n",
    "            'optimizer': scenario['optimizer'],\n",
    "            'learning_rate': scenario['learning_rate'],\n",
    "            'epochs': scenario['epochs'],\n",
    "            'train_accuracy': final_train_acc,\n",
    "            'train_loss': final_train_loss,\n",
    "            'val_accuracy': final_val_acc,\n",
    "            'val_loss': final_val_loss,\n",
    "            'history': history.history\n",
    "        }\n",
    "        # Calculate precision, recall, F1 score on validation set\n",
    "        y_pred = model.predict(val_gen, verbose=0)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        # Recreate validation dataset to extract labels (predict consumed the dataset)\n",
    "        val_ds_for_labels = tf.keras.utils.image_dataset_from_directory(\n",
    "            config.DATASET_DIR,\n",
    "            validation_split=1.0 - scenario['split_ratio'],\n",
    "            subset='validation',\n",
    "            seed=SEED,\n",
    "            image_size=(config.IMG_SIZE_MOBILE, config.IMG_SIZE_MOBILE),\n",
    "            batch_size=config.BATCH_SIZE,\n",
    "            shuffle=False\n",
    "        )\n",
    "        # Extract true labels from the fresh validation dataset (original dataset was consumed by predict())\n",
    "        y_true = np.concatenate([y for x, y in val_ds_for_labels], axis=0)\n",
    "        y_true = np.argmax(y_true, axis=1)[:len(y_pred_classes)]\n",
    "        # Calculate metrics (weighted average for multi-class)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred_classes, average='weighted', zero_division=0\n",
    "        )\n",
    "        # Add metrics to result dictionary\n",
    "        result['precision'] = float(precision)\n",
    "        result['recall'] = float(recall)\n",
    "        result['f1_score'] = float(f1)\n",
    "        results.append(result)\n",
    "        print(f\"\\n  \u2713 Scenario {scenario['id']} completed!\")\n",
    "        print(f\"    Final Train Accuracy: {final_train_acc:.4f}\")\n",
    "        print(f\"    Final Val Accuracy: {final_val_acc:.4f}\")\n",
    "        # Save model for this scenario in models directory\n",
    "        os.makedirs(config.MODELS_DIR, exist_ok=True)\n",
    "        scenario_model_path = os.path.join(\n",
    "            config.MODELS_DIR,\n",
    "            f\"model_scenario_{scenario['id']:02d}_{scenario['split_name'].replace(':', '-')}_{scenario['optimizer']}_lr{scenario['learning_rate']}.keras\"\n",
    "        )\n",
    "        model.save(scenario_model_path)\n",
    "        print(f\"    \u2713 Model saved: {scenario_model_path}\")\n",
    "        # Save best model as training progresses\n",
    "        if final_val_acc > best_val_acc:\n",
    "            best_val_acc = final_val_acc\n",
    "            best_scenario_id = scenario['id']\n",
    "            best_model_path = os.path.join(config.MODELS_DIR, 'best_model.keras')\n",
    "            model.save(best_model_path)\n",
    "            print(f\"    \u2713 New best model saved: {best_model_path}\")\n",
    "        # Clear memory\n",
    "        del model\n",
    "        del train_gen\n",
    "        del val_gen\n",
    "        tf.keras.backend.clear_session()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n  \u2717 Scenario {scenario['id']} failed: {str(e)}\")\n",
    "        results.append({\n",
    "            'scenario_id': scenario['id'],\n",
    "            'split_ratio': scenario['split_name'],\n",
    "            'optimizer': scenario['optimizer'],\n",
    "            'learning_rate': scenario['learning_rate'],\n",
    "            'epochs': scenario['epochs'],\n",
    "            'error': str(e)\n",
    "        })\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"TRAINING COMPLETED: {len([r for r in results if 'val_accuracy' in r])}/{len(scenarios)} scenarios successful\")\n",
    "print(f\"{'='*70}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb092b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 7. PREPARE RESULTS DATAFRAME ------------------\n",
    "\n",
    "# Filter successful results\n",
    "successful_results = [r for r in results if 'val_accuracy' in r]\n",
    "\n",
    "if len(successful_results) == 0:\n",
    "    print(\"\u26a0 No successful training runs to analyze!\")\n",
    "else:\n",
    "    # Create DataFrame\n",
    "    df_results = pd.DataFrame([{\n",
    "        'Scenario_ID': r['scenario_id'],\n",
    "        'Split_Ratio': r['split_ratio'],\n",
    "        'Optimizer': r['optimizer'],\n",
    "        'Learning_Rate': r['learning_rate'],\n",
    "        'Epochs': r['epochs'],\n",
    "        'Train_Accuracy': r['train_accuracy'],\n",
    "        'Val_Accuracy': r['val_accuracy'],\n",
    "        'Train_Loss': r['train_loss'],\n",
    "        'Val_Loss': r['val_loss'],\n",
    "        'Precision': r.get('precision', 0.0),\n",
    "        'Recall': r.get('recall', 0.0),\n",
    "        'F1_Score': r.get('f1_score', 0.0)\n",
    "    } for r in successful_results])\n",
    "    \n",
    "    # Sort by validation accuracy\n",
    "    df_results = df_results.sort_values('Val_Accuracy', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    results_csv = os.path.join(config.OUTPUT_DIR, 'scenario_results.csv')\n",
    "    df_results.to_csv(results_csv, index=False)\n",
    "    \n",
    "    # Save detailed history to JSON\n",
    "    history_json = os.path.join(config.OUTPUT_DIR, 'training_history.json')\n",
    "    with open(history_json, 'w') as f:\n",
    "        json.dump(successful_results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\n\u2713 Results saved:\")\n",
    "    print(f\"  - CSV: {results_csv}\")\n",
    "    print(f\"  - JSON: {history_json}\")\n",
    "    \n",
    "    # Display top 10\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"TOP 10 SCENARIOS BY VALIDATION ACCURACY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(df_results.head(10).to_string(index=False))\n",
    "    print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 8. VISUALIZATION: TOP 10 BAR CHART ------------------\n",
    "\n",
    "if len(successful_results) > 0:\n",
    "    # Get top 10 scenarios\n",
    "    top_10 = df_results.head(10).copy()\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create labels with all info\n",
    "    top_10['Label'] = top_10.apply(\n",
    "        lambda x: f\"S{x['Scenario_ID']}: {x['Split_Ratio']}, {x['Optimizer']}, LR={x['Learning_Rate']}\", \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Create horizontal bar chart\n",
    "    bars = plt.barh(range(len(top_10)), top_10['Val_Accuracy'], color='steelblue', alpha=0.8)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, val) in enumerate(zip(bars, top_10['Val_Accuracy'])):\n",
    "        plt.text(val + 0.005, i, f'{val:.4f}', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.yticks(range(len(top_10)), top_10['Label'])\n",
    "    plt.xlabel('Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "    plt.title('Top 10 Scenarios by Validation Accuracy', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    fig_path = os.path.join(config.OUTPUT_DIR, 'top_10_scenarios.png')\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n\u2713 Top 10 bar chart saved: {fig_path}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\u26a0 No results to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93870539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 9. VISUALIZATION: TOP 3 TRAINING CURVES ------------------\n",
    "\n",
    "if len(successful_results) >= 3:\n",
    "    top_3_ids = df_results.head(3)['Scenario_ID'].tolist()\n",
    "    top_3_results = [r for r in successful_results if r['scenario_id'] in top_3_ids]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    for idx, result in enumerate(top_3_results):\n",
    "        ax = axes[idx]\n",
    "        history = result['history']\n",
    "        epochs_range = range(1, len(history['accuracy']) + 1)\n",
    "        \n",
    "        # Plot accuracy\n",
    "        ax.plot(epochs_range, history['accuracy'], 'b-', label='Train Accuracy', linewidth=2)\n",
    "        ax.plot(epochs_range, history['val_accuracy'], 'r-', label='Val Accuracy', linewidth=2)\n",
    "        \n",
    "        ax.set_title(\n",
    "            f\"Scenario {result['scenario_id']}: {result['split_ratio']}\\n\"\n",
    "            f\"{result['optimizer']}, LR={result['learning_rate']}, Val Acc={result['val_accuracy']:.4f}\",\n",
    "            fontsize=11, fontweight='bold'\n",
    "        )\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Accuracy', fontsize=10)\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    fig_path = os.path.join(config.OUTPUT_DIR, 'top_3_training_curves.png')\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\u2713 Top 3 training curves saved: {fig_path}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\u26a0 Not enough results to plot top 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea32bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 10. VISUALIZATION: CONFUSION MATRIX FOR BEST SCENARIO ------------------\n",
    "if len(successful_results) > 0:\n",
    "    # Get best scenario\n",
    "    best_scenario_id = df_results.iloc[0]['Scenario_ID']\n",
    "    best_result = [r for r in successful_results if r['scenario_id'] == best_scenario_id][0]\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EVALUATING BEST SCENARIO: {best_scenario_id}\")\n",
    "    print(f\"  Split: {best_result['split_ratio']}\")\n",
    "    print(f\"  Optimizer: {best_result['optimizer']}\")\n",
    "    print(f\"  Learning Rate: {best_result['learning_rate']}\")\n",
    "    print(f\"  Val Accuracy: {best_result['val_accuracy']:.4f}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    if isinstance(best_result['split_ratio'], str):\n",
    "        split_num = float(best_result['split_ratio'].split(':')[0]) / 100.0\n",
    "    else:\n",
    "        split_num = best_result['split_ratio']\n",
    "    # Recreate data generators for best scenario\n",
    "    train_gen, val_gen, class_names = create_data_generators(\n",
    "        config.WORK_DIR,\n",
    "        train_ratio=split_num,\n",
    "        img_size=config.IMG_SIZE_MOBILE,\n",
    "        batch_size=config.BATCH_SIZE\n",
    "    )\n",
    "    # Load best model if available; otherwise retrain and save\n",
    "    if best_model_path and os.path.exists(best_model_path):\n",
    "        best_model = tf.keras.models.load_model(best_model_path)\n",
    "        print(f\"\\n\u2713 Loaded best model from: {best_model_path}\")\n",
    "    else:\n",
    "        best_model = build_feature_extraction_model(\n",
    "            num_classes=config.NUM_CLASSES,\n",
    "            img_size=config.IMG_SIZE_MOBILE,\n",
    "            optimizer_name=best_result['optimizer'],\n",
    "            learning_rate=best_result['learning_rate'],\n",
    "            dropout_rate=config.DROPOUT_RATE\n",
    "        )\n",
    "        early_stop = callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=0\n",
    "        )\n",
    "        best_model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=best_result['epochs'],\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0\n",
    "        )\n",
    "        os.makedirs(config.MODELS_DIR, exist_ok=True)\n",
    "        best_model_path = os.path.join(config.MODELS_DIR, 'best_model.keras')\n",
    "        best_model.save(best_model_path)\n",
    "        print(f\"\\n\u2713 Best model saved: {best_model_path}\")\n",
    "    # Generate predictions\n",
    "    y_pred = best_model.predict(val_gen, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    # Recreate validation dataset to extract labels (predict consumed the dataset)\n",
    "    val_ds_for_labels = tf.keras.utils.image_dataset_from_directory(\n",
    "        config.WORK_DIR,\n",
    "        validation_split=1.0 - split_num,\n",
    "        subset='validation',\n",
    "        seed=SEED,\n",
    "        image_size=(config.IMG_SIZE_MOBILE, config.IMG_SIZE_MOBILE),\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    # Extract true labels from the fresh validation dataset (original dataset was consumed by predict())\n",
    "    y_true = np.concatenate([y for x, y in val_ds_for_labels], axis=0)\n",
    "    y_true = np.argmax(y_true, axis=1)[:len(y_pred_classes)]\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    # Get class names\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'Confusion Matrix - Best Scenario {best_scenario_id}\\n'\n",
    "              f'{best_result[\"split_ratio\"]}, {best_result[\"optimizer\"]}, LR={best_result[\"learning_rate\"]}',\n",
    "              fontsize=13, fontweight='bold', pad=15)\n",
    "    plt.ylabel('True Label', fontsize=11, fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontsize=11, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    # Save figure\n",
    "    fig_path = os.path.join(config.OUTPUT_DIR, 'best_scenario_confusion_matrix.png')\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n\u2713 Confusion matrix saved: {fig_path}\")\n",
    "    plt.show()\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred_classes, target_names=class_names))\n",
    "    # Cleanup\n",
    "    del best_model\n",
    "    tf.keras.backend.clear_session()\n",
    "else:\n",
    "    print(\"\u26a0 No results to evaluate\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 11. FINAL SUMMARY ------------------\n",
    "\n",
    "if len(successful_results) > 0:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"EXPERIMENT SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total Scenarios: {len(scenarios)}\")\n",
    "    print(f\"Successful Runs: {len(successful_results)}\")\n",
    "    print(f\"Failed Runs: {len(scenarios) - len(successful_results)}\")\n",
    "    print(f\"\\nBest Scenario: {df_results.iloc[0]['Scenario_ID']}\")\n",
    "    print(f\"  Configuration: {df_results.iloc[0]['Split_Ratio']}, \"\n",
    "          f\"{df_results.iloc[0]['Optimizer']}, LR={df_results.iloc[0]['Learning_Rate']}\")\n",
    "    print(f\"  Validation Accuracy: {df_results.iloc[0]['Val_Accuracy']:.4f}\")\n",
    "    print(f\"\\nWorst Scenario: {df_results.iloc[-1]['Scenario_ID']}\")\n",
    "    print(f\"  Configuration: {df_results.iloc[-1]['Split_Ratio']}, \"\n",
    "          f\"{df_results.iloc[-1]['Optimizer']}, LR={df_results.iloc[-1]['Learning_Rate']}\")\n",
    "    print(f\"  Validation Accuracy: {df_results.iloc[-1]['Val_Accuracy']:.4f}\")\n",
    "    \n",
    "    # Performance comparison by optimizer\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"PERFORMANCE BY OPTIMIZER\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for opt in ['Adam', 'SGD']:\n",
    "        opt_results = df_results[df_results['Optimizer'] == opt]\n",
    "        if len(opt_results) > 0:\n",
    "            print(f\"{opt}:\")\n",
    "            print(f\"  Mean Val Accuracy: {opt_results['Val_Accuracy'].mean():.4f}\")\n",
    "            print(f\"  Best Val Accuracy: {opt_results['Val_Accuracy'].max():.4f}\")\n",
    "            print(f\"  Worst Val Accuracy: {opt_results['Val_Accuracy'].min():.4f}\")\n",
    "    \n",
    "    # Performance comparison by split ratio\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"PERFORMANCE BY SPLIT RATIO\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for split in ['90:10', '80:20', '70:30']:\n",
    "        split_results = df_results[df_results['Split_Ratio'] == split]\n",
    "        if len(split_results) > 0:\n",
    "            print(f\"{split}:\")\n",
    "            print(f\"  Mean Val Accuracy: {split_results['Val_Accuracy'].mean():.4f}\")\n",
    "            print(f\"  Best Val Accuracy: {split_results['Val_Accuracy'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"All outputs saved to:\", config.OUTPUT_DIR)\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"\\n\u2713 Multi-scenario transfer learning experiment completed successfully!\")\n",
    "else:\n",
    "    print(\"\\n\u26a0 No successful results to summarize\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}